{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part3:Evaluation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOP2k635MFW5ez2YmfVb/wF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Import Required Libraries\"\"\"\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "AX_eqOdkavqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5g41mpJGcWDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation\n",
        "In this section we will evaluate our semantic segmentation models by applying the following measures: \n",
        "\n",
        "\n",
        "\n",
        "*   Accuracy\n",
        "*   Dice Coefficient (F1 Score)\n",
        "*   Jaccard index (IoU)\n",
        "*   Sensitivty\n",
        "*   Specificity\n",
        "*   Precision\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jDAyw210Z-GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (512, 256))\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_BAYER_GR2GRAY)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (512, 256))\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_BAYER_GR2GRAY)\n",
        "    x = x > 0.5\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = x.astype(np.int32)\n",
        "    return x\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "  union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "  dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
        "  return dice\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  # Loading model \n",
        "  with CustomObjectScope({'dice_coef': dice_coef}):\n",
        "    model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab_Notebooks/GP/Models/3rdm_att_UNet_50epochs.h5\")\n",
        "\n",
        "    # Loading the original images and segmentation map \n",
        "    test_x = sorted(glob(\"/content/drive/MyDrive/Colab_Notebooks/GP/dataset/testing_set/images/*\"))\n",
        "    test_y = sorted(glob(\"/content/drive/MyDrive/Colab_Notebooks/GP/dataset/testing_set/segmentation_map/*\"))\n",
        "\n",
        "    # Predicting the mask and calculating metrics values\n",
        "    SCORE = []\n",
        "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "\n",
        "      #Extracing the image name\n",
        "      image_name = x.split(\"/\")[-1]\n",
        "\n",
        "      # Reading the original image and segmentation map \n",
        "      x = read_image(x)\n",
        "      y = read_mask(y)\n",
        "\n",
        "      # Predicting the mask\n",
        "      y_pred = model.predict(x)[0] > 0.5\n",
        "      y_pred = np.squeeze(y_pred, axis=-1)\n",
        "      y_pred = y_pred.astype(np.int32)\n",
        "\n",
        "      # Flattening the numpy arrays, all measures requires to convert images to 1d array \n",
        "      y = y.flatten()\n",
        "      y_pred = y_pred.flatten()\n",
        "\n",
        "      # Calculating metrics values \n",
        "      acc_value = accuracy_score(y, y_pred)\n",
        "      f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "      jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "      recall_value_sensitivty = recall_score(y, y_pred,pos_label=1 )#labels=[0, 1], average=\"binary\"\n",
        "      recall_value_specificity = recall_score(y, y_pred, pos_label=0)\n",
        "      precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\",zero_division=1)\n",
        "      SCORE.append([image_name, acc_value, f1_value, jac_value, recall_value_sensitivty,recall_value_specificity, precision_value])\n",
        "\n",
        "      # Metrics values \n",
        "      score = [s[1:]for s in SCORE]\n",
        "\n",
        "    \"\"\"Uncomment the measure you need: mean,median,std\"\"\"\n",
        "    score = np.mean(score, axis=0)\n",
        "    #score = np.std(score, axis=0)\n",
        "    #score = np.median(score, axis=0)\n",
        "    \n",
        "    print(f\"\\nAccuracy: {score[0]:0.5f}\")    \n",
        "    print(f\"Dice Coefficient: {score[1]:0.5f}\")# F1\n",
        "    print(f\"Jaccard index: {score[2]:0.5f}\")# iou\n",
        "    print(f\"Sensitivty: {score[3]:0.5f}\") #Recall \n",
        "    print(f\"Specificity: {score[4]:0.5f}\")\n",
        "    print(f\"Precision: {score[5]:0.5f}\")\n",
        "\n",
        "    # Saving results of each image to a csv file \n",
        "    df = pd.DataFrame(SCORE, columns=[\"Image\", \"Accuracy\", \"F1\", \"Jaccard\", \"Sensitivty\",\"Specificity\", \"Precision\"])\n",
        "    df.to_csv(\"score.csv\")"
      ],
      "metadata": {
        "id": "0UTojqKjXPBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Support References:\n",
        "\n",
        "\n",
        "*   https://www.youtube.com/watch?v=zLNkJqVZiiU\n",
        "*   https://github.com/nikhilroxtomar/Evaluating-the-Semantic-Segmentation-Models/blob/main/eval.py\n",
        "*   https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zgB4ddfsxkwG"
      }
    }
  ]
}
